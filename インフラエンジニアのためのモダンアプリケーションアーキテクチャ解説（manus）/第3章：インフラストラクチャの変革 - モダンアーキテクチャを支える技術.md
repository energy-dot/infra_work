## 第3章：インフラストラクチャの変革 - モダンアーキテクチャを支える技術

前章では、API化とマイクロサービス化がもたらすアプリケーション側の変革について詳述しました。アプリケーションがより小さく、独立し、分散化されたコンポーネントの集合体へと進化する中で、それを支えるインフラストラクチャもまた、従来のアプローチから大きな転換を迫られています。本章では、モダンアプリケーションアーキテクチャの実現に不可欠な、コンテナ技術、Infrastructure as Code (IaC)、サーバーレスアーキテクチャ、そしてクラウドネイティブネットワーキングといった中核的なインフラ技術について、その概念、メリット、主要なツール、そしてインフラエンジニアが押さえておくべきポイントを詳細に解説します。特に、ユーザーからのご要望に基づき、技術的な詳細や従来との比較、プロダクトごとの特徴や必要性、そして適宜箇条書きを交えながら、分かりやすさを重視して説明を進めます。

### 3.1. コンテナ技術：ポータビリティと効率性の追求

マイクロサービスアーキテクチャの普及を技術的に強力に後押ししたのが、コンテナ技術、特にDockerとKubernetesの登場です。コンテナは、アプリケーションとその依存関係（ライブラリ、設定ファイルなど）をひとまとめにし、どんな環境でも同じように動作させることを可能にする技術です。これにより、開発環境から本番環境への移行がスムーズになり、「開発環境では動いたのに本番では動かない」といった問題を大幅に削減できます。

**Dockerの基本**

Dockerは、コンテナを作成・管理するための代表的なプラットフォームです。その主要な構成要素と概念は以下の通りです。

*   **Dockerイメージ (Image)**: アプリケーションを実行するために必要な全てのファイルシステム、ライブラリ、環境変数、設定などを含む読み取り専用のテンプレートです。Dockerfileというテキストファイルにイメージの構成手順を記述し、`docker build` コマンドで作成します。
*   **Dockerコンテナ (Container)**: Dockerイメージから作成される、実際にアプリケーションが動作する実行環境のインスタンスです。イメージは読み取り専用ですが、コンテナは書き込み可能なレイヤーを持ち、プロセスを実行できます。`docker run` コマンドで起動します。
*   **Docker Hub / レジストリ (Registry)**: Dockerイメージを保存・共有するためのリポジトリサービスです。Docker Hubは公式のパブリックレジストリですが、プライベートなレジストリ（例：AWS ECR, Google Container Registry, Azure Container Registry, Harbor）を構築・利用することも可能です。

Dockerを利用するメリットは多岐にわたります。

*   **ポータビリティ**: 一度イメージを作成すれば、Dockerが動作する環境であればどこでも同じようにアプリケーションを実行できます。
*   **軽量性と高速性**: 従来の仮想マシン(VM)がOS全体をエミュレートするのに対し、コンテナはホストOSのカーネルを共有するため、起動が非常に速く、リソース消費も少ないです。
*   **環境分離**: 各コンテナは独立したファイルシステムとプロセス空間を持つため、互いに影響を与えません。
*   **再現性**: Dockerfileによって環境構築手順がコード化されるため、誰でも同じ環境を再現できます。

**Kubernetes：コンテナオーケストレーションのデファクトスタンダード**

個々のコンテナを管理するのはDockerで十分ですが、多数のマイクロサービスが多数のコンテナとして動作する本番環境では、これらのコンテナ群を効率的にデプロイ、スケーリング、管理、監視するための「コンテナオーケストレーション」ツールが必要になります。そのデファクトスタンダードとなっているのがKubernetes（K8sと略されることもあります）です。

Kubernetesは、Googleが社内で長年利用してきたコンテナ管理システムBorgをベースに開発され、現在はCloud Native Computing Foundation (CNCF) がホストしています。その主な機能とアーキテクチャは以下の通りです。

*   **主な機能**:
    *   **自動デプロイメントとロールバック**: アプリケーションの新しいバージョンを宣言的にデプロイし、問題があれば以前のバージョンに自動的にロールバックできます。
    *   **自動スケーリング**: CPU使用率などのメトリクスに基づいて、コンテナの数を自動的に増減させることができます (Horizontal Pod Autoscaler)。
    *   **自己修復 (Self-healing)**: 異常終了したコンテナを自動的に再起動したり、応答しないノード上のコンテナを別のノードに再スケジュールしたりします。
    *   **サービスディスカバリとロードバランシング**: 各サービスに安定したIPアドレスとDNS名を提供し、複数のコンテナインスタンスへのトラフィックを分散します。
    *   **設定とシークレット管理**: アプリケーションの設定情報やパスワードなどの機密情報を安全に管理・配布できます (ConfigMap, Secret)。
    *   **ストレージオーケストレーション**: ローカルストレージやクラウドプロバイダーの永続ストレージをコンテナにマウントできます (PersistentVolume, PersistentVolumeClaim)。

*   **アーキテクチャの主要コンポーネント**:
    *   **マスターノード (Master Node / Control Plane)**: クラスタ全体を管理・制御するコンポーネント群が動作します。
        *   `kube-apiserver`: Kubernetes APIのフロントエンド。全ての操作の窓口となります。
        *   `etcd`: クラスタの状態（設定情報、デプロイメント情報など）を保存する分散キーバリューストア。
        *   `kube-scheduler`: 新しく作成されたPodを、リソース要件や制約に基づいて適切なワーカーノードに割り当てます。
        *   `kube-controller-manager`: ノードコントローラー、レプリケーションコントローラーなど、様々なコントローラーを実行し、クラスタの状態を望ましい状態に維持します。
    *   **ワーカーノード (Worker Node)**: 実際にコンテナ化されたアプリケーション（Pod）が実行されるノードです。
        *   `kubelet`: マスターノードからの指示に従い、Pod内のコンテナを起動・停止・監視します。
        *   `kube-proxy`: 各ノードでネットワークルールを維持し、Serviceへのネットワークトラフィックを適切なPodに転送します。
        *   `コンテナランタイム (Container Runtime)`: Docker、containerd、CRI-Oなど、実際にコンテナを実行するソフトウェア。

*   **主要なリソースオブジェクト**:
    *   **Pod**: Kubernetesにおけるデプロイの最小単位。一つ以上のコンテナ（通常は密接に関連するコンテナ群）と、それらが共有するストレージやネットワークリソースを含みます。
    *   **Service**: Podの論理的な集合と、それらにアクセスするための固定的なエンドポイント（IPアドレス、DNS名、ポート）を定義します。ロードバランシング機能も提供します。
    *   **Deployment**: PodやReplicaSet（Podのレプリカ数を管理）の宣言的な定義と、ローリングアップデートやロールバックといったデプロイ戦略を管理します。
    *   **Namespace**: 単一のKubernetesクラスタ内でリソースを論理的に分割・分離するための仕組み。開発、ステージング、本番といった環境分離や、チームごとのリソース分離に利用されます。

Kubernetesを導入するメリットは大きいですが、学習コストや運用複雑性も高いため、小規模なシステムや専門知識を持つチームがいない場合は、AWS ECS, Azure Container Instances, Google Cloud Runといったよりシンプルなコンテナ実行環境や、マネージドKubernetesサービス（AWS EKS, Azure AKS, Google GKE）の利用を検討することも重要です。

インフラエンジニアは、Dockerによるコンテナ化の基本を理解した上で、Kubernetesのアーキテクチャ、主要なリソースオブジェクト、そして運用管理（デプロイ、スケーリング、モニタリング、トラブルシューティング）に関する深い知識と実践的なスキルを身につける必要があります。

### 3.2. Infrastructure as Code (IaC)：インフラ構成の自動化と再現性

モダンアプリケーションアーキテクチャでは、インフラストラクチャもまた、アプリケーションコードと同様にバージョン管理され、自動的にプロビジョニング・構成されることが求められます。これを実現するのが「Infrastructure as Code (IaC)」というプラクティスです。

IaCは、インフラの構成（サーバー、ネットワーク、ストレージ、データベース、ロードバランサーなど）を、手作業ではなく、コード（設定ファイルやスクリプト）によって定義・管理するアプローチです。これにより、以下のような多くのメリットが得られます。

*   **自動化による効率向上**: 手作業によるインフラ構築・変更作業を排除し、プロビジョニング時間を大幅に短縮します。
*   **再現性と一貫性**: 同じコードからは常に同じ構成のインフラが作成されるため、環境間の差異（例：開発環境と本番環境の差異）をなくし、一貫性を保ちます。
*   **バージョン管理と変更追跡**: インフラ構成をGitなどのバージョン管理システムで管理することで、変更履歴を追跡し、必要に応じて以前の状態にロールバックすることが容易になります。
*   **テスト容易性**: インフラ構成コードに対してテストを実施することで、本番環境への適用前に問題を検出できます。
*   **コスト削減**: 手作業によるミスを減らし、運用効率を向上させることで、人件費や機会損失を削減します。
*   **ドキュメント化**: インフラ構成コードそのものが、インフラの仕様を示すドキュメントとして機能します。

IaCを実現するための主要なツールとアプローチには、以下のようなものがあります。

**代表的なIaCツール**

*   **Terraform (HashiCorp)**:
    *   **特徴**: クラウドプロバイダー（AWS, Azure, GCPなど）やオンプレミス環境を含む多様なインフラリソースを、宣言的な設定言語（HCL: HashiCorp Configuration Language）で定義・管理できます。プロバイダープラグインアーキテクチャにより、対応リソースが豊富です。
    *   **アプローチ**: 宣言的（Desired State）。ユーザーは「最終的にどういう状態にしたいか」を記述し、Terraformが現在の状態との差分を計算（`terraform plan`）し、それを実現するための具体的な操作を実行（`terraform apply`）します。
    *   **ユースケース**: クラウドインフラ全体のプロビジョニング、マルチクラウド環境の管理など。
*   **Ansible (Red Hat)**:
    *   **特徴**: Pythonベースの構成管理ツール。エージェントレスで動作し（SSH経由で接続）、Playbookと呼ばれるYAML形式のファイルに構成手順を記述します。シンプルで学習しやすいのが特徴です。
    *   **アプローチ**: 手続き的（Procedural）な記述も可能ですが、冪等性（同じ操作を何度実行しても結果が変わらないこと）を意識した宣言的な記述が推奨されます。
    *   **ユースケース**: サーバーの初期設定、ミドルウェアのインストール、アプリケーションのデプロイ、パッチ適用など、既存のサーバーに対する構成変更やタスク実行。
*   **AWS CloudFormation, Azure Resource Manager (ARM) Templates, Google Cloud Deployment Manager**:
    *   **特徴**: 各クラウドプロバイダーが提供するネイティブなIaCサービス。JSONまたはYAML形式でインフラ構成を定義します。プロバイダー固有のサービスとの連携がスムーズです。
    *   **アプローチ**: 宣言的。
    *   **ユースケース**: 特定のクラウドプロバイダー内でのインフラ構築・管理。
*   **Pulumi**:
    *   **特徴**: TypeScript, Python, Go, C#といった汎用プログラミング言語を使用してインフラを定義できる比較的新しいIaCツール。既存のプログラミング言語の機能（ループ、条件分岐、関数、クラスなど）を活用できるため、より複雑なロジックを記述しやすいです。
    *   **アプローチ**: 宣言的（コードで記述するが、最終的な状態を定義する）。
    *   **ユースケース**: ソフトウェア開発者がインフラ構築にも関わる場合や、複雑なインフラ構成をプログラム的に管理したい場合。

**宣言的アプローチ vs 手続き的アプローチ**

IaCツールのアプローチは、大きく「宣言的」と「手続き的」に分けられます。

*   **宣言的 (Declarative)**: 「最終的にどういう状態（What）にしたいか」を定義します。ツールは現在の状態と比較し、差分を埋めるために必要な処理を自動的に判断して実行します。TerraformやCloudFormationが代表例です。冪等性が担保されやすいというメリットがあります。
*   **手続き的 (Procedural)**: 「どのように（How）その状態に到達するか」という手順をステップバイステップで記述します。Ansible（Playbook）やChef（Recipe）、Puppet（Manifest）などがこれに分類されることもありますが、これらのツールも冪等性を意識した宣言的な記述が可能です。シェルスクリプトは典型的な手続き的アプローチです。

モダンなIaCでは、宣言的アプローチが主流となりつつあります。

**GitOpsの実践**

GitOpsは、IaCのプラクティスをさらに発展させ、インフラストラクチャとアプリケーションの構成管理・デプロイメントの中心としてGitリポジトリを利用する運用モデルです。主な原則は以下の通りです。

1.  **システム全体の望ましい状態をGitで宣言的に記述する**: インフラ構成、アプリケーション設定、Kubernetesマニフェストなど、全てをGitリポジトリで管理します。
2.  **Gitリポジトリが唯一の信頼できる情報源 (Single Source of Truth)**: 手動での直接的な環境変更は行わず、全ての変更はGitへのコミットとプルリクエストを通じて行われます。
3.  **承認された変更は自動的にシステムに適用される**: Gitリポジトリへの変更がマージされると、自動化されたプロセス（CI/CDパイプラインや専用のGitOpsオペレーター）がそれを検知し、実際の環境に適用します。
4.  **ソフトウェアエージェントによる状態同期と逸脱検知**: システム内で動作するエージェントが、Gitリポジトリで定義された望ましい状態と実際の環境の状態を継続的に比較し、差異があればアラートを発したり、自動的に修正したりします。

GitOpsを実践することで、インフラ変更の透明性、監査性、再現性が向上し、より信頼性の高い運用が可能になります。FluxCDやArgo CDは、Kubernetes環境でGitOpsを実現するための代表的なツールです。

インフラエンジニアは、これらのIaCツールやプラクティスを習得し、手作業によるインフラ管理から脱却することで、より迅速かつ安全に、ビジネスの要求に応じたインフラを提供できるようになります。

### 3.3. サーバーレスアーキテクチャ：インフラ管理からの解放

サーバーレスアーキテクチャは、開発者がサーバーのプロビジョニングや管理といったインフラ運用を意識することなく、アプリケーションコードの実行に集中できるようにするクラウドコンピューティングの実行モデルです。これは「サーバーが存在しない」という意味ではなく、「開発者がサーバーを直接管理する必要がない」という意味合いです。

**Function as a Service (FaaS) の概念**

サーバーレスの中核をなすのが「Function as a Service (FaaS)」です。FaaSは、特定のイベント（HTTPリクエスト、データベースの変更、メッセージキューへのメッセージ到着など）に応じて、短い時間実行される小さなコード片（関数）を実行するサービスです。代表的なFaaSプラットフォームには以下のようなものがあります。

*   **AWS Lambda**
*   **Azure Functions**
*   **Google Cloud Functions**
*   **Knative (Kubernetesベースのサーバーレスプラットフォーム)**

FaaSの主な特徴とメリットは以下の通りです。

*   **イベント駆動**: 関数は特定のイベントによってトリガーされます。
*   **ステートレス**: 関数自体は状態を持たず、必要なデータは外部のストレージやデータベースから取得します。
*   **自動スケーリング**: リクエストの量に応じて、プラットフォームが自動的に関数のインスタンス数をスケールアップ/ダウンします。トラフィックがない場合は、インスタンスがゼロになることもあります（スケール・トゥ・ゼロ）。
*   **従量課金**: 関数が実際に実行された時間とリソース消費量に対してのみ課金されます。アイドル時間には課金されません。
*   **インフラ管理の削減**: サーバーのOSパッチ適用、ミドルウェアのアップデート、キャパシティプランニングといったインフラ管理作業から解放されます。

**サーバーレスのメリットとデメリット、ユースケース**

*   **メリット**:
    *   **開発の迅速化**: インフラを意識せずにビジネスロジックの実装に集中できます。
    *   **コスト効率**: 実行時間ベースの課金により、特にトラフィックが断続的な場合にコストを最適化できます。
    *   **高いスケーラビリティと可用性**: クラウドプロバイダーがスケーリングと可用性を管理します。
*   **デメリットと考慮事項**:
    *   **コールドスタート**: 長時間呼び出されなかった関数が最初に呼び出される際に、起動に時間がかかることがあります（レイテンシへの影響）。
    *   **実行時間の制限**: 通常、関数の実行時間には上限があります（例：AWS Lambdaは最大15分）。長時間の処理には不向きです。
    *   **ステート管理の複雑性**: 関数がステートレスであるため、状態管理は外部のデータベースやストレージサービスに依存します。
    *   **ベンダーロックイン**: 特定のクラウドプロバイダーのFaaSプラットフォームに依存しやすくなります。
    *   **ローカルテストとデバッグの難しさ**: クラウド環境特有の動作をローカルで完全に再現するのが難しい場合があります。
    *   **監視とトラブルシューティング**: 分散された多数の関数を監視し、問題の原因を特定するのが複雑になることがあります（オブザーバビリティの重要性）。
*   **主なユースケース**:
    *   **Web APIバックエンド**: APIゲートウェイと連携し、RESTful APIのバックエンド処理を実装。
    *   **データ処理・ETL**: ファイルアップロードやデータベース変更をトリガーとしたデータ変換・加工処理。
    *   **リアルタイムファイル処理**: 画像のリサイズ、動画のトランスコーディングなど。
    *   **チャットボットやAlexaスキルなどのバックエンドロジック**。
    *   **IoTデバイスからのデータ収集と処理**。
    *   **定時実行タスク（Cronジョブの代替）**。

**Backend as a Service (BaaS) との連携**

サーバーレスアーキテクチャは、FaaSだけでなく、「Backend as a Service (BaaS)」とも密接に関連しています。BaaSは、モバイルアプリやWebアプリケーションで共通して必要となるバックエンド機能（認証、データベース、ストレージ、プッシュ通知など）をAPIとして提供するサービスです。AWS Amplify, Google Firebase, Azure Mobile Appsなどが代表例です。

開発者は、BaaSを利用することで、これらのバックエンド機能を自分で構築・管理する手間を省き、フロントエンド開発やFaaSによるカスタムロジックの実装に集中できます。FaaSとBaaSを組み合わせることで、より迅速かつ効率的にフルサーバーレスなアプリケーションを構築することが可能です。

インフラエンジニアにとって、サーバーレスアーキテクチャは直接的なサーバー管理業務を減らす一方で、関数のデプロイメントパイプラインの構築、IAMによる権限管理、APIゲートウェイの設定、そして分散された関数の監視とロギング戦略の策定といった新しい役割が求められます。

### 3.4. クラウドネイティブネットワーキング：動的なサービス間通信の実現

マイクロサービスやコンテナ、サーバーレスといったクラウドネイティブなアーキテクチャでは、アプリケーションコンポーネントが動的に生成・消滅し、ネットワーク上の位置も常に変化します。このような環境で、サービス間の信頼性の高い通信を確保し、トラフィックを適切に管理・監視するためには、従来の静的なネットワーク構成とは異なる、新しいネットワーキングのアプローチが必要になります。これが「クラウドネイティブネットワーキング」です。

**サービスメッシュの役割と機能**

クラウドネイティブネットワーキングの中核技術の一つが「サービスメッシュ」です。サービスメッシュは、マイクロサービス間の全てのネットワーク通信を管理し、信頼性、可観測性、セキュリティを向上させるための専用のインフラストラクチャレイヤーです。代表的なサービスメッシュの実装には、Istio, Linkerd, Consul Connectなどがあります。

サービスメッシュは通常、各マイクロサービスのPodに「サイドカープロキシ」（例：Envoy Proxy）をデプロイし、これらのプロキシがサービス間の実際の通信を代行します。アプリケーションコード自体はネットワーク通信の詳細を意識する必要がありません。サービスメッシュの主な機能は以下の通りです。

*   **トラフィック管理 (Traffic Management)**:
    *   **動的なルーティング**: リクエストのヘッダー情報や重み付けに基づいて、トラフィックを異なるバージョンのサービスに振り分ける（例：カナリアリリース、A/Bテスト）。
    *   **リトライとタイムアウト**: 失敗したリクエストを自動的にリトライしたり、応答のないサービスへのリクエストをタイムアウトさせたりします。
    *   **サーキットブレーカー**: 障害が発生しているサービスへのリクエストを一時的に遮断し、障害の連鎖を防ぎます。
    *   **ミラーリング (シャドウイング)**: 本番トラフィックの一部を別のサービス（例：テスト環境の新しいバージョン）に複製して送信し、影響を観測します。
*   **可観測性 (Observability)**:
    *   **メトリクス収集**: サービス間のリクエスト数、レイテンシ、エラーレートなどの詳細なメトリクスを自動的に収集します。
    *   **分散トレーシング**: 複数のサービスにまたがるリクエストの処理経路を追跡し、ボトルネックやエラー箇所を特定しやすくします (例: Jaeger, Zipkinとの連携)。
    *   **アクセルログ**: 全てのサービス間通信の詳細なログを記録します。
*   **セキュリティ (Security)**:
    *   **相互TLS認証 (mTLS)**: サービス間の通信を自動的に暗号化し、相互に認証することで、なりすましや盗聴を防ぎます。
    *   **認可ポリシー**: どのサービスがどのサービスと通信できるかといった詳細なアクセスコントロールポリシーを定義・強制します。

**APIゲートウェイとの違いと連携**

サービスメッシュとAPIゲートウェイは、どちらもマイクロサービス環境におけるネットワーク通信を管理する役割を担いますが、そのスコープと主な目的が異なります。

*   **APIゲートウェイ**: 主に外部（クライアントアプリケーション、サードパーティ）からマイクロサービス群へのトラフィック（いわゆるNorth-Southトラフィック）を管理します。認証・認可、レートリミット、リクエスト変換などが主な機能です。
*   **サービスメッシュ**: 主にマイクロサービス間の内部通信（いわゆるEast-Westトラフィック）を管理します。高度なトラフィック制御、mTLSによるセキュリティ、詳細な可観測性の提供が主な機能です。

多くの場合、APIゲートウェイとサービスメッシュは連携して使用されます。外部からのリクエストはまずAPIゲートウェイで受け付けられ、認証などの処理が行われた後、内部のサービスメッシュを通じて各マイクロサービスにルーティングされるといった構成が一般的です。

**マイクロサービス環境におけるネットワークセキュリティ**

動的で分散化されたマイクロサービス環境では、従来の境界型セキュリティモデル（ファイアウォールで内部ネットワークを保護する考え方）だけでは不十分です。代わりに、「ゼロトラストセキュリティ」の原則に基づいたアプローチが求められます。これは、「何も信頼せず、全てを検証する (Never Trust, Always Verify)」という考え方です。

マイクロサービス環境におけるネットワークセキュリティの主なポイントは以下の通りです。

*   **mTLSによる通信の暗号化と認証**: サービスメッシュなどを活用し、全てのサービス間通信をデフォルトで暗号化・認証します。
*   **最小権限の原則に基づくアクセスコントロール**: 各サービスは、業務上必要な最小限の他のサービスとのみ通信できるように、詳細なネットワークポリシーを設定します。
*   **APIセキュリティ**: APIゲートウェイやWeb Application Firewall (WAF) を利用して、OWASP Top 10のような一般的なWebアプリケーションの脆弱性からAPIを保護します。
*   **シークレット管理**: APIキー、データベース認証情報、TLS証明書などの機密情報を安全に管理・配布します (例: HashiCorp Vault, Kubernetes Secrets)。
*   **ネットワークセグメンテーション**: KubernetesのNamespaceやネットワークポリシーを利用して、異なる環境やアプリケーション間のネットワーク分離を強化します。
*   **継続的な監視とログ分析**: ネットワークトラフィックやセキュリティイベントを常に監視し、異常を早期に検知して対応します。

インフラエンジニアは、これらのクラウドネイティブネットワーキング技術を理解し、アプリケーションの要件に応じて適切なツールやパターンを選択・実装することで、変化に強く、安全で、観測可能なサービス間通信基盤を構築する責任を負います。

本章では、コンテナ、IaC、サーバーレス、クラウドネイティブネットワーキングといった、モダンアプリケーションアーキテクチャを支える主要なインフラ技術について解説しました。次章では、これらの技術を活用してシステムを運用する上で不可欠となる「オブザーバビリティ（可観測性）」について、その重要性と具体的な実現方法を掘り下げていきます。

